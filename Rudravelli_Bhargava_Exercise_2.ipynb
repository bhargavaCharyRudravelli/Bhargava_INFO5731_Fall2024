{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bhargavaCharyRudravelli/Bhargava_INFO5731_Fall2024/blob/main/Rudravelli_Bhargava_Exercise_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DymRJbxDBCnf"
      },
      "source": [
        "# **INFO5731 In-class Exercise 2**\n",
        "\n",
        "The purpose of this exercise is to understand users' information needs, and then collect data from different sources for analysis by implementing web scraping using Python.\n",
        "\n",
        "**Expectations**:\n",
        "*   Students are expected to complete the exercise during lecture period to meet the active participation criteria of the course.\n",
        "*   Use the provided .*ipynb* document to write your code & respond to the questions. Avoid generating a new file.\n",
        "*   Write complete answers and run all the cells before submission.\n",
        "*   Make sure the submission is \"clean\"; *i.e.*, no unnecessary code cells.\n",
        "*   Once finished, allow shared rights from top right corner (*see Canvas for details*).\n",
        "\n",
        "**Total points**: 40\n",
        "\n",
        "**Deadline**: This in-class exercise is due at the end of the day tomorrow, at 11:59 PM.\n",
        "\n",
        "**Late submissions will have a penalty of 10% of the marks for each day of late submission. , and no requests will be answered. Manage your time accordingly.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 1 (10 Points)\n",
        "Describe an interesting research question (or practical question or something innovative) you have in mind, what kind of data should be collected to answer the question(s)? Specify the amount of data needed for analysis. Provide detailed steps for collecting and saving the data."
      ],
      "metadata": {
        "id": "FBKvD6O_TY6e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install beautifulsoup4 requests pandas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sUc9DOzB-g2W",
        "outputId": "d986b8da-1ed0-4ca1-87b0-77df3d158184"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.12.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.1.4)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.8.30)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "# Collecting data from a website to get the collection of india districts census\n",
        "# step:1 generating headers for HTTP requests to web servers\n",
        "headers = {\n",
        "    \"User-Agent\": \"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:123.0) Gecko/20100101 Firefox/123.0\",\n",
        "    \"Accept\": \"text/html\",\n",
        "    \"Connection\": \"keep-alive\"\n",
        "}\n",
        "# step:2 create a list to store all rows of data\n",
        "store_data = []\n",
        "\n",
        "# step:3 logic for collecting the data from url and extracting the data\n",
        "for i in range(1, 40):\n",
        "    url = f'https://www.census2011.co.in/district.php?page={i}' # link for collecting the data\n",
        "    response = requests.get(url, headers=headers)\n",
        "    response_result = BeautifulSoup(response.content, 'html.parser')\n",
        "    tables = response_result.find_all('table', class_='filter table table-striped table-hover')\n",
        "\n",
        "    # loop for multiple rows\n",
        "    for table in tables:\n",
        "        # Extract headers\n",
        "        country_titles = table.find_all('th')\n",
        "        country_table_titles = [title.text.strip() for title in country_titles]\n",
        "\n",
        "        # Extract rows\n",
        "        rows = table.find_all('tr')\n",
        "        for row in rows[1:]:  # Skip header row\n",
        "            row_data = row.find_all('td')\n",
        "            individual_rowdata = [data.text.strip() for data in row_data]\n",
        "            store_data.append(individual_rowdata)\n",
        "\n",
        "# step:4 create a DataFrame from the exttrcted data\n",
        "df = pd.DataFrame(store_data, columns=country_table_titles)\n",
        "\n",
        "# step:5 Print & save the DataFrame\n",
        "print(df)\n",
        "# Optionally save to a CSV file\n",
        "df.to_csv('census_data.csv', index=False)"
      ],
      "metadata": {
        "id": "cikVKDXdTbzE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2874b1bd-88e6-43e9-a2fe-092c548b6402"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       #                    District                        State  Population  \\\n",
            "0      1                       Thane                  Maharashtra  11,060,148   \n",
            "1      2  North Twenty Four Parganas                  West Bengal  10,009,781   \n",
            "2      3                   Bangalore                    Karnataka   9,621,551   \n",
            "3      4                        Pune                  Maharashtra   9,429,408   \n",
            "4      5             Mumbai Suburban                  Maharashtra   9,356,962   \n",
            "..   ...                         ...                          ...         ...   \n",
            "635  636                    Nicobars  Andaman and Nicobar Islands      36,842   \n",
            "636  637                 Upper Siang            Arunachal Pradesh      35,320   \n",
            "637  638             Lahul and Spiti             Himachal Pradesh      31,564   \n",
            "638  639                       Anjaw            Arunachal Pradesh      21,167   \n",
            "639  640               Dibang Valley            Arunachal Pradesh       8,004   \n",
            "\n",
            "       Growth Sex-Ratio Literacy  \n",
            "0     36.01 %       886    84.53  \n",
            "1     12.04 %       955    84.06  \n",
            "2     47.18 %       916    87.67  \n",
            "3     30.37 %       915    86.15  \n",
            "4      8.29 %       860    89.91  \n",
            "..        ...       ...      ...  \n",
            "635  -12.42 %       777    78.06  \n",
            "636    5.87 %       889    59.99  \n",
            "637   -5.00 %       903    76.81  \n",
            "638   14.19 %       839    56.46  \n",
            "639   10.07 %       813    64.10  \n",
            "\n",
            "[640 rows x 7 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 2 (10 Points)\n",
        "Write Python code to collect a dataset of 1000 samples related to the question discussed in Question 1."
      ],
      "metadata": {
        "id": "E9RqrlwdTfvl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# write your answer here\n",
        "import pandas as pd\n",
        "sample_data = df.sample(n=600)\n",
        "print(sample_data)\n",
        "print(sample_data.head())"
      ],
      "metadata": {
        "id": "4XvRknixTh1g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc26ca41-3701-452e-d516-9babb1368ce4"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       #       District             State Population   Growth Sex-Ratio  \\\n",
            "267  268  Ramabai Nagar     Uttar Pradesh  1,796,184  14.89 %       865   \n",
            "43    44  Visakhapatnam    Andhra Pradesh  4,290,589  11.96 %      1006   \n",
            "502  503  North Tripura           Tripura    693,947  17.44 %       967   \n",
            "40    41           Agra     Uttar Pradesh  4,418,797  22.05 %       868   \n",
            "330  331         Kangra  Himachal Pradesh  1,510,075  12.77 %      1012   \n",
            "..   ...            ...               ...        ...      ...       ...   \n",
            "144  145        Bhojpur             Bihar  2,728,407  21.63 %       907   \n",
            "190  191        Bikaner         Rajasthan  2,363,937  41.19 %       905   \n",
            "67    68      Sultanpur     Uttar Pradesh  3,797,117  18.11 %       983   \n",
            "51    52      Anantapur    Andhra Pradesh  4,081,148  12.10 %       977   \n",
            "204  205         Nawada             Bihar  2,219,146  22.63 %       939   \n",
            "\n",
            "    Literacy  \n",
            "267    75.78  \n",
            "43     66.91  \n",
            "502    87.50  \n",
            "40     71.58  \n",
            "330    85.67  \n",
            "..       ...  \n",
            "144    70.47  \n",
            "190    65.13  \n",
            "67     69.27  \n",
            "51     63.57  \n",
            "204    59.76  \n",
            "\n",
            "[600 rows x 7 columns]\n",
            "       #       District             State Population   Growth Sex-Ratio  \\\n",
            "267  268  Ramabai Nagar     Uttar Pradesh  1,796,184  14.89 %       865   \n",
            "43    44  Visakhapatnam    Andhra Pradesh  4,290,589  11.96 %      1006   \n",
            "502  503  North Tripura           Tripura    693,947  17.44 %       967   \n",
            "40    41           Agra     Uttar Pradesh  4,418,797  22.05 %       868   \n",
            "330  331         Kangra  Himachal Pradesh  1,510,075  12.77 %      1012   \n",
            "\n",
            "    Literacy  \n",
            "267    75.78  \n",
            "43     66.91  \n",
            "502    87.50  \n",
            "40     71.58  \n",
            "330    85.67  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03jb4GZsBkBS"
      },
      "source": [
        "## Question 3 (10 Points)\n",
        "Write Python code to collect 1000 articles from Google Scholar (https://scholar.google.com/), Microsoft Academic (https://academic.microsoft.com/home), or CiteSeerX (https://citeseerx.ist.psu.edu/index), or Semantic Scholar (https://www.semanticscholar.org/), or ACM Digital Libraries (https://dl.acm.org/) with the keyword \"XYZ\". The articles should be published in the last 10 years (2014-2024).\n",
        "\n",
        "The following information from the article needs to be collected:\n",
        "\n",
        "(1) Title of the article\n",
        "\n",
        "(2) Venue/journal/conference being published\n",
        "\n",
        "(3) Year\n",
        "\n",
        "(4) Authors\n",
        "\n",
        "(5) Abstract"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install requests pandas\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u5lOgXhiWHqi",
        "outputId": "670435fa-bde6-41f7-82db-2d598232553b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.1.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.8.30)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "YaGLbSHHB8Ej",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05562c30-2420-4277-c714-0571af20b81a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Design Patterns for Data-Driven News Articles\n",
            "<div class=\"issue-item__detail\"><a href=\"/doi/proceedings/10.1145/3613904\" title=\"CHI '24: Proceedings of the CHI Conference on Human Factors in Computing Systems\"><span class=\"epub-section__title\">CHI '24: Proceedings of the CHI Conference on Human Factors in Computing Systems</span></a><span class=\"dot-separator\"><span>May 2024, </span><span>Article No.: 231</span>, <span>Pages 1â€“16</span></span><span><a class=\"issue-item__doi dot-separator\" href=\"https://doi.org/10.1145/3613904.3641916\">https://doi.org/10.1145/3613904.3641916</a></span></div>\n",
            "CHI '24: Proceedings of the CHI Conference on Human Factors in Computing Systems\n",
            "None\n",
            "Mining the History Sections of Wikipedia Articles on Science and Technology\n",
            "<div class=\"issue-item__detail\"><a href=\"/doi/proceedings/10.5555/3694718\" title=\"JCDL '23: Proceedings of the 2023 ACM/IEEE Joint Conference on Digital Libraries\"><span class=\"epub-section__title\">JCDL '23: Proceedings of the 2023 ACM/IEEE Joint Conference on Digital Libraries</span></a><span class=\"dot-separator\"><span>June 2024, </span><span>Pages 200â€“204</span></span><span><a class=\"issue-item__doi dot-separator\" href=\"https://doi.org/10.1109/JCDL57899.2023.00037\">https://doi.org/10.1109/JCDL57899.2023.00037</a></span></div>\n",
            "JCDL '23: Proceedings of the 2023 ACM/IEEE Joint Conference on Digital Libraries\n",
            "None\n",
            "Drug Target Extraction from Biomedical Articles Based on a Two-Stage Cascading Framework\n",
            "<div class=\"issue-item__detail\"><a href=\"/doi/proceedings/10.5555/3694718\" title=\"JCDL '23: Proceedings of the 2023 ACM/IEEE Joint Conference on Digital Libraries\"><span class=\"epub-section__title\">JCDL '23: Proceedings of the 2023 ACM/IEEE Joint Conference on Digital Libraries</span></a><span class=\"dot-separator\"><span>June 2024, </span><span>Pages 245â€“246</span></span><span><a class=\"issue-item__doi dot-separator\" href=\"https://doi.org/10.1109/JCDL57899.2023.00044\">https://doi.org/10.1109/JCDL57899.2023.00044</a></span></div>\n",
            "JCDL '23: Proceedings of the 2023 ACM/IEEE Joint Conference on Digital Libraries\n",
            "None\n",
            "Co-Creating Question-and-Answer Style Articles with Large Language Models for Research Promotion\n",
            "<div class=\"issue-item__detail\"><a href=\"/doi/proceedings/10.1145/3643834\" title=\"DIS '24: Proceedings of the 2024 ACM Designing Interactive Systems Conference\"><span class=\"epub-section__title\">DIS '24: Proceedings of the 2024 ACM Designing Interactive Systems Conference</span></a><span class=\"dot-separator\"><span>July 2024, </span><span>Pages 975â€“994</span></span><span><a class=\"issue-item__doi dot-separator\" href=\"https://doi.org/10.1145/3643834.3660705\">https://doi.org/10.1145/3643834.3660705</a></span></div>\n",
            "DIS '24: Proceedings of the 2024 ACM Designing Interactive Systems Conference\n",
            "None\n",
            "AI-Generated News Articles Based on Large Language Models\n",
            "<div class=\"issue-item__detail\"><a href=\"/doi/proceedings/10.1145/3661638\" title=\"AISNS '23: Proceedings of the 2023 International Conference on Artificial Intelligence, Systems and Network Security\"><span class=\"epub-section__title\">AISNS '23: Proceedings of the 2023 International Conference on Artificial Intelligence, Systems and Network Security</span></a><span class=\"dot-separator\"><span>December 2023, </span><span>Pages 82â€“87</span></span><span><a class=\"issue-item__doi dot-separator\" href=\"https://doi.org/10.1145/3661638.3661654\">https://doi.org/10.1145/3661638.3661654</a></span></div>\n",
            "AISNS '23: Proceedings of the 2023 International Conference on Artificial Intelligence, Systems and Network Security\n",
            "None\n",
            "Geographic Information Retrieval Using Wikipedia Articles\n",
            "<div class=\"issue-item__detail\"><a href=\"/doi/proceedings/10.1145/3543507\" title=\"WWW '23: Proceedings of the ACM Web Conference 2023\"><span class=\"epub-section__title\">WWW '23: Proceedings of the ACM Web Conference 2023</span></a><span class=\"dot-separator\"><span>April 2023, </span><span>Pages 3331â€“3341</span></span><span><a class=\"issue-item__doi dot-separator\" href=\"https://doi.org/10.1145/3543507.3583469\">https://doi.org/10.1145/3543507.3583469</a></span></div>\n",
            "WWW '23: Proceedings of the ACM Web Conference 2023\n",
            "None\n",
            "Automatic Quality Assessment of Wikipedia Articlesâ€”A Systematic Literature Review\n",
            "<div class=\"issue-item__detail\"><a href=\"/toc/csur/2024/56/4\" title=\"ACM Computing Surveys (CSUR)\"><span class=\"epub-section__title\">ACM Computing Surveys (CSUR), Volume 56, Issue 4</span></a><span class=\"dot-separator\"><span>Article No.: 95</span>, <span>Pages 1â€“37</span></span><span><a class=\"issue-item__doi dot-separator\" href=\"https://doi.org/10.1145/3625286\">https://doi.org/10.1145/3625286</a></span></div>\n",
            "ACM Computing Surveys (CSUR), Volume 56, Issue 4\n",
            "None\n",
            "Implementation of Domain Adaptation for Keyword Determination of Scientific Articles Based on Multilabel BERT\n",
            "<div class=\"issue-item__detail\"><a href=\"/doi/proceedings/10.1145/3626641\" title=\"SIET '23: Proceedings of the 8th International Conference on Sustainable Information Engineering and Technology\"><span class=\"epub-section__title\">SIET '23: Proceedings of the 8th International Conference on Sustainable Information Engineering and Technology</span></a><span class=\"dot-separator\"><span>October 2023, </span><span>Pages 173â€“180</span></span><span><a class=\"issue-item__doi dot-separator\" href=\"https://doi.org/10.1145/3626641.3626927\">https://doi.org/10.1145/3626641.3626927</a></span></div>\n",
            "SIET '23: Proceedings of the 8th International Conference on Sustainable Information Engineering and Technology\n",
            "None\n",
            "Descartes: Generating Short Descriptions of Wikipedia Articles\n",
            "<div class=\"issue-item__detail\"><a href=\"/doi/proceedings/10.1145/3543507\" title=\"WWW '23: Proceedings of the ACM Web Conference 2023\"><span class=\"epub-section__title\">WWW '23: Proceedings of the ACM Web Conference 2023</span></a><span class=\"dot-separator\"><span>April 2023, </span><span>Pages 1446â€“1456</span></span><span><a class=\"issue-item__doi dot-separator\" href=\"https://doi.org/10.1145/3543507.3583220\">https://doi.org/10.1145/3543507.3583220</a></span></div>\n",
            "WWW '23: Proceedings of the ACM Web Conference 2023\n",
            "None\n",
            "Analysis of The Irish Times Newspaper Articles\n",
            "<div class=\"issue-item__detail\"><a href=\"/doi/proceedings/10.1145/3524383\" title=\"ICBDE '22: Proceedings of the 5th International Conference on Big Data and Education\"><span class=\"epub-section__title\">ICBDE '22: Proceedings of the 5th International Conference on Big Data and Education</span></a><span class=\"dot-separator\"><span>February 2022, </span><span>Pages 353â€“360</span></span><span><a class=\"issue-item__doi dot-separator\" href=\"https://doi.org/10.1145/3524383.3524443\">https://doi.org/10.1145/3524383.3524443</a></span></div>\n",
            "ICBDE '22: Proceedings of the 5th International Conference on Big Data and Education\n",
            "None\n",
            "Future Timelines: Extraction and Visualization of Future-related Content From News Articles\n",
            "<div class=\"issue-item__detail\"><a href=\"/doi/proceedings/10.1145/3616855\" title=\"WSDM '24: Proceedings of the 17th ACM International Conference on Web Search and Data Mining\"><span class=\"epub-section__title\">WSDM '24: Proceedings of the 17th ACM International Conference on Web Search and Data Mining</span></a><span class=\"dot-separator\"><span>March 2024, </span><span>Pages 1082â€“1085</span></span><span><a class=\"issue-item__doi dot-separator\" href=\"https://doi.org/10.1145/3616855.3635693\">https://doi.org/10.1145/3616855.3635693</a></span></div>\n",
            "WSDM '24: Proceedings of the 17th ACM International Conference on Web Search and Data Mining\n",
            "None\n",
            "Automatically Temporal Labeled Data Generation Using Positional Lexicon Expansion for Focus Time Estimation of News Articles\n",
            "<div class=\"issue-item__detail\"><a href=\"/toc/tallip/2024/23/5\" title=\"ACM Transactions on Asian and Low-Resource Language Information Processing (TALLIP)\"><span class=\"epub-section__title\">ACM Transactions on Asian and Low-Resource Language Information Processing (TALLIP), Volume 23, Issue 5</span></a><span class=\"dot-separator\"><span>Article No.: 64</span>, <span>Pages 1â€“20</span></span><span><a class=\"issue-item__doi dot-separator\" href=\"https://doi.org/10.1145/3568164\">https://doi.org/10.1145/3568164</a></span></div>\n",
            "ACM Transactions on Asian and Low-Resource Language Information Processing (TALLIP), Volume 23, Issue 5\n",
            "None\n",
            "DynamicESG: A Dataset for Dynamically Unearthing ESG Ratings from News Articles\n",
            "<div class=\"issue-item__detail\"><a href=\"/doi/proceedings/10.1145/3583780\" title=\"CIKM '23: Proceedings of the 32nd ACM International Conference on Information and Knowledge Management\"><span class=\"epub-section__title\">CIKM '23: Proceedings of the 32nd ACM International Conference on Information and Knowledge Management</span></a><span class=\"dot-separator\"><span>October 2023, </span><span>Pages 5412â€“5416</span></span><span><a class=\"issue-item__doi dot-separator\" href=\"https://doi.org/10.1145/3583780.3615118\">https://doi.org/10.1145/3583780.3615118</a></span></div>\n",
            "CIKM '23: Proceedings of the 32nd ACM International Conference on Information and Knowledge Management\n",
            "None\n",
            "Put Your Voice on Stage: Personalized Headline Generation for News Articles\n",
            "<div class=\"issue-item__detail\"><a href=\"/toc/tkdd/2024/18/3\" title=\"ACM Transactions on Knowledge Discovery from Data (TKDD)\"><span class=\"epub-section__title\">ACM Transactions on Knowledge Discovery from Data (TKDD), Volume 18, Issue 3</span></a><span class=\"dot-separator\"><span>Article No.: 54</span>, <span>Pages 1â€“20</span></span><span><a class=\"issue-item__doi dot-separator\" href=\"https://doi.org/10.1145/3629168\">https://doi.org/10.1145/3629168</a></span></div>\n",
            "ACM Transactions on Knowledge Discovery from Data (TKDD), Volume 18, Issue 3\n",
            "None\n",
            "A Category-agnostic Graph Attention-based Approach for Determining Notability of Articles for Wikipedia\n",
            "<div class=\"issue-item__detail\"><a href=\"/doi/proceedings/10.1145/3589335\" title=\"WWW '24: Companion Proceedings of the ACM Web Conference 2024\"><span class=\"epub-section__title\">WWW '24: Companion Proceedings of the ACM Web Conference 2024</span></a><span class=\"dot-separator\"><span>May 2024, </span><span>Pages 911â€“914</span></span><span><a class=\"issue-item__doi dot-separator\" href=\"https://doi.org/10.1145/3589335.3651461\">https://doi.org/10.1145/3589335.3651461</a></span></div>\n",
            "WWW '24: Companion Proceedings of the ACM Web Conference 2024\n",
            "None\n",
            "Classification of advertisement articles using sentiment analysis: (Research-based on Korean natural language processing and deep learning technology)\n",
            "<div class=\"issue-item__detail\"><a href=\"/doi/proceedings/10.1145/3582768\" title=\"NLPIR '22: Proceedings of the 2022 6th International Conference on Natural Language Processing and Information Retrieval\"><span class=\"epub-section__title\">NLPIR '22: Proceedings of the 2022 6th International Conference on Natural Language Processing and Information Retrieval</span></a><span class=\"dot-separator\"><span>December 2022, </span><span>Pages 84â€“88</span></span><span><a class=\"issue-item__doi dot-separator\" href=\"https://doi.org/10.1145/3582768.3582800\">https://doi.org/10.1145/3582768.3582800</a></span></div>\n",
            "NLPIR '22: Proceedings of the 2022 6th International Conference on Natural Language Processing and Information Retrieval\n",
            "None\n",
            "Making Data-Driven Articles more Accessible: An Active Preference Learning Approach to Data Fact Personalization\n",
            "<div class=\"issue-item__detail\"><a href=\"/doi/proceedings/10.1145/3563657\" title=\"DIS '23: Proceedings of the 2023 ACM Designing Interactive Systems Conference\"><span class=\"epub-section__title\">DIS '23: Proceedings of the 2023 ACM Designing Interactive Systems Conference</span></a><span class=\"dot-separator\"><span>July 2023, </span><span>Pages 1353â€“1366</span></span><span><a class=\"issue-item__doi dot-separator\" href=\"https://doi.org/10.1145/3563657.3595986\">https://doi.org/10.1145/3563657.3595986</a></span></div>\n",
            "DIS '23: Proceedings of the 2023 ACM Designing Interactive Systems Conference\n",
            "None\n",
            "Cryptocurrency Price Prediction Using Twitter and News Articles Analysis\n",
            "<div class=\"issue-item__detail\"><a href=\"/doi/proceedings/10.1145/3549206\" title=\"IC3-2022: Proceedings of the 2022 Fourteenth International Conference on Contemporary Computing\"><span class=\"epub-section__title\">IC3-2022: Proceedings of the 2022 Fourteenth International Conference on Contemporary Computing</span></a><span class=\"dot-separator\"><span>August 2022, </span><span>Pages 225â€“233</span></span><span><a class=\"issue-item__doi dot-separator\" href=\"https://doi.org/10.1145/3549206.3549248\">https://doi.org/10.1145/3549206.3549248</a></span></div>\n",
            "IC3-2022: Proceedings of the 2022 Fourteenth International Conference on Contemporary Computing\n",
            "None\n",
            "Domain Adaptation in Nested Named Entity Recognition From Scientific Articles in Agriculture\n",
            "<div class=\"issue-item__detail\"><a href=\"/doi/proceedings/10.1145/3628797\" title=\"SOICT '23: Proceedings of the 12th International Symposium on Information and Communication Technology\"><span class=\"epub-section__title\">SOICT '23: Proceedings of the 12th International Symposium on Information and Communication Technology</span></a><span class=\"dot-separator\"><span>December 2023, </span><span>Pages 48â€“55</span></span><span><a class=\"issue-item__doi dot-separator\" href=\"https://doi.org/10.1145/3628797.3628958\">https://doi.org/10.1145/3628797.3628958</a></span></div>\n",
            "SOICT '23: Proceedings of the 12th International Symposium on Information and Communication Technology\n",
            "None\n",
            "Automatic Extraction of Patterns in Digital News Articles of Femicides occurred in Mexico by Text Mining Techniques\n",
            "<div class=\"issue-item__detail\"><a href=\"/doi/proceedings/10.1145/3616855\" title=\"WSDM '24: Proceedings of the 17th ACM International Conference on Web Search and Data Mining\"><span class=\"epub-section__title\">WSDM '24: Proceedings of the 17th ACM International Conference on Web Search and Data Mining</span></a><span class=\"dot-separator\"><span>March 2024, </span><span>Pages 1204â€“1205</span></span><span><a class=\"issue-item__doi dot-separator\" href=\"https://doi.org/10.1145/3616855.3636503\">https://doi.org/10.1145/3616855.3636503</a></span></div>\n",
            "WSDM '24: Proceedings of the 17th ACM International Conference on Web Search and Data Mining\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "# write your answer here\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "\n",
        "url = \"https://dl.acm.org/action/doSearch?AllField=articles\"\n",
        "response=requests.get(url)\n",
        "response=response.content\n",
        "soup=BeautifulSoup(response,'html.parser')\n",
        "context=soup.find_all('div',class_='issue-item__content-right')\n",
        "for contexts in context:\n",
        "  articleName=contexts.find('h5',class_= 'issue-item__title').text\n",
        "  print(articleName)\n",
        "\n",
        "  conference=contexts.find('div',class_= 'issue-item__detail')\n",
        "  print(conference)\n",
        "  venue=conference.find('span',class_= 'epub-section__title').text\n",
        "  print(venue)\n",
        "  abstract=contexts.find('div','issue-item__abstract truncate-text trunc-done')\n",
        "  print(abstract)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJDe71iLB616"
      },
      "source": [
        "## Question 4A (10 Points)\n",
        "Develop Python code to collect data from social media platforms like Reddit, Instagram, Twitter (formerly known as X), Facebook, or any other. Use hashtags, keywords, usernames, or user IDs to gather the data.\n",
        "\n",
        "\n",
        "\n",
        "Ensure that the collected data has more than four columns.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install praw pandas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9qQ6VBaKJHAr",
        "outputId": "c6729317-8156-4f0e-91dc-7a5c8082ce27"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting praw\n",
            "  Downloading praw-7.7.1-py3-none-any.whl.metadata (9.8 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.1.4)\n",
            "Collecting prawcore<3,>=2.1 (from praw)\n",
            "  Downloading prawcore-2.4.0-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting update-checker>=0.18 (from praw)\n",
            "  Downloading update_checker-0.18.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: websocket-client>=0.54.0 in /usr/local/lib/python3.10/dist-packages (from praw) (1.8.0)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: requests<3.0,>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from prawcore<3,>=2.1->praw) (2.32.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (2024.8.30)\n",
            "Downloading praw-7.7.1-py3-none-any.whl (191 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m191.0/191.0 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading prawcore-2.4.0-py3-none-any.whl (17 kB)\n",
            "Downloading update_checker-0.18.0-py3-none-any.whl (7.0 kB)\n",
            "Installing collected packages: update-checker, prawcore, praw\n",
            "Successfully installed praw-7.7.1 prawcore-2.4.0 update-checker-0.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "MtKskTzbCLaU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ba5bb4d-1d92-405d-e7c0-7ff397ba95b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ntscraper in /usr/local/lib/python3.10/dist-packages (0.3.17)\n",
            "Requirement already satisfied: requests>=2.28 in /usr/local/lib/python3.10/dist-packages (from ntscraper) (2.32.3)\n",
            "Requirement already satisfied: beautifulsoup4>=4.11 in /usr/local/lib/python3.10/dist-packages (from ntscraper) (4.12.3)\n",
            "Requirement already satisfied: lxml>=4.9 in /usr/local/lib/python3.10/dist-packages (from ntscraper) (4.9.4)\n",
            "Requirement already satisfied: tqdm>=4.66 in /usr/local/lib/python3.10/dist-packages (from ntscraper) (4.66.5)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4>=4.11->ntscraper) (2.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->ntscraper) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->ntscraper) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->ntscraper) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->ntscraper) (2024.8.30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Testing instances: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:14<00:00,  1.12it/s]\n",
            "INFO:root:No instance specified, using random instance https://nitter.lucabased.xyz\n",
            "INFO:root:Current stats for Elon Musk: 4 tweets, 0 threads...\n",
            "INFO:root:Current stats for Elon Musk: 7 tweets, 0 threads...\n",
            "INFO:root:Current stats for Elon Musk: 13 tweets, 0 threads...\n",
            "INFO:root:Current stats for Elon Musk: 14 tweets, 0 threads...\n",
            "WARNING:root:Empty page on https://nitter.lucabased.xyz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                 Text  \\\n",
            "0   I like to share my picture with you all I hope...   \n",
            "1   As if #Biden couldnâ€™t have #Musk arrested righ...   \n",
            "2   Dear #Elon #Musk, is This creature, #Kamala #H...   \n",
            "3   The Tesla Diner is almost ready to open its do...   \n",
            "4   ðŸ‘€ All eyes will be on $BYTE this cycle and wil...   \n",
            "5                              Ø¨Ø« Ù…Ø¨Ø§Ø´Ø± ðŸ”¥ðŸ”¥ #Elon Musk   \n",
            "6   Well, #Elon Musk, I take that back, you are fu...   \n",
            "7   #Biden #Elon is doing it again ðŸ¤¬ðŸ¤¬ðŸ¤¬  Die Posts ...   \n",
            "8   #Shiba Inuâ€™s Lucie discusses paid listings on ...   \n",
            "9   Also troubling #Elon Musk is you barring the a...   \n",
            "10  Ð—ÐµÐ»ÐµÐ½ÑÑŒÐºÐ¸Ð¹, Ð´Ðµ Ñ‚Ð²Ñ–Ð¹ Ð¿Ð»Ð°Ð½ Ð¿Ñ€Ð¾Ñ‚Ð¸ Ð Ð¾ÑÑ–Ñ—? ÐœÐ°Ñ€Ð½Ð¾ Ð»Ð¸...   \n",
            "11  Ð§Ð°ÑÐ¸ Ð²Ð¸Ð¿Ñ€Ð¾Ð±ÑƒÐ²Ð°Ð½ÑŒ Ð½Ðµ Ð·Ð°ÐºÑ–Ð½Ñ‡ÑƒÑŽÑ‚ÑŒÑÑ, Ñ– Ð·Ð´Ð°Ñ”Ñ‚ÑŒÑÑ, ...   \n",
            "12  Itâ€™s Solar oâ€™clock . Switch to smart life toda...   \n",
            "13  Howâ€™s â€œmuh free speechâ€ doinâ€™ this week, any u...   \n",
            "\n",
            "                           Date  Likes  Retweets  \n",
            "0   Sep 18, 2024 Â· 12:46 AM UTC      0         0  \n",
            "1   Sep 18, 2024 Â· 12:05 AM UTC      0         0  \n",
            "2    Sep 17, 2024 Â· 9:59 PM UTC      0         0  \n",
            "3    Sep 17, 2024 Â· 9:46 PM UTC      2         1  \n",
            "4    Aug 31, 2024 Â· 4:22 PM UTC    142        57  \n",
            "5    Sep 17, 2024 Â· 8:13 PM UTC      2         0  \n",
            "6    Sep 17, 2024 Â· 7:51 PM UTC      0         0  \n",
            "7    Jul 21, 2024 Â· 8:48 PM UTC    424       128  \n",
            "8    Sep 17, 2024 Â· 7:32 PM UTC      1         0  \n",
            "9    Sep 17, 2024 Â· 7:28 PM UTC      0         0  \n",
            "10   Sep 17, 2024 Â· 7:23 PM UTC      0         0  \n",
            "11   Sep 17, 2024 Â· 7:19 PM UTC      0         0  \n",
            "12   Sep 17, 2024 Â· 6:23 PM UTC      2         0  \n",
            "13   Sep 17, 2024 Â· 6:08 PM UTC      1         0  \n"
          ]
        }
      ],
      "source": [
        "# write your answer here\n",
        "from os import statvfs\n",
        "!pip install ntscraper\n",
        "import pandas as pd\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from ntscraper import Nitter\n",
        "\n",
        "# step:1 generating headers for HTTP requests to web servers\n",
        "Headers = {\n",
        "    \"User-Agent\": \"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:123.0) Gecko/20100101 Firefox/123.0\",\n",
        "    \"Accept\": \"text/html\",\n",
        "    \"Connection\": \"keep-alive\"\n",
        "}\n",
        "# get the connection from twitter(Nitter is an alternative front-end for Twitter)\n",
        "chary=Nitter()\n",
        "tweets=chary.get_tweets('Elon Musk',mode='hashtag',number=33) # get the tweets from twitter\n",
        "data=[]\n",
        "# loop for no.of tweets\n",
        "for i in tweets['tweets']:\n",
        "  tweetdata={\n",
        "      'Text':i['text'],\n",
        "      'Date':i['date'],\n",
        "      'Likes':i['stats']['likes'],\n",
        "      'Retweets':i['stats']['retweets']\n",
        "  }\n",
        "  data.append(tweetdata)\n",
        "  df=pd.DataFrame(data)\n",
        "print(df)\n",
        "#we can save the  formated as csv\n",
        "df.to_csv('chary.csv')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55W9AMdXCSpV"
      },
      "source": [
        "## Question 4B (10 Points)\n",
        "If you encounter challenges with Question-4 web scraping using Python, employ any online tools such as ParseHub or Octoparse for data extraction. Introduce the selected tool, outline the steps for web scraping, and showcase the final output in formats like CSV or Excel.\n",
        "\n",
        "\n",
        "\n",
        "Upload a document (Word or PDF File) in any shared storage (preferably UNT OneDrive) and add the publicly accessible link in the below code cell.\n",
        "\n",
        "Please only choose one option for question 4. If you do both options, we will grade only the first one"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I57NXsauCec2"
      },
      "outputs": [],
      "source": [
        "# write your answer here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mandatory Question"
      ],
      "metadata": {
        "id": "sZOhks1dXWEe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Important: Reflective Feedback on Web Scraping and Data Collection**\n",
        "\n",
        "\n",
        "\n",
        "Please share your thoughts and feedback on the web scraping and data collection exercises you have completed in this assignment. Consider the following points in your response:\n",
        "\n",
        "\n",
        "\n",
        "Learning Experience: Describe your overall learning experience in working on web scraping tasks. What were the key concepts or techniques you found most beneficial in understanding the process of extracting data from various online sources?\n",
        "\n",
        "\n",
        "\n",
        "Challenges Encountered: Were there specific difficulties in collecting data from certain websites, and how did you overcome them? If you opted for the non-coding option, share your experience with the chosen tool.\n",
        "\n",
        "\n",
        "\n",
        "Relevance to Your Field of Study: How might the ability to gather and analyze data from online sources enhance your work or research?\n",
        "\n",
        "**(no grading of your submission if this question is left unanswered)**"
      ],
      "metadata": {
        "id": "eqmHVEwaWhbV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Write your response here.\n",
        "\n",
        "Taken too much of time to understand and implement the code.\n",
        "It looks and this is encountered difficulties to write this code and taken many websites to understand.\n",
        "I learned the ways for implementing headers in python code and also learned few rest calls that can be done through the headers.\n",
        "I understood that web scraping is the basic fundamental concept in python and i am good in learning this.\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "akAVJn9YBTQT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "e86b3b3b-9c16-4aca-cf5e-6d8afd66dd33"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nWrite your response here.\\n\\nTaken too much of time to understand and implement the code. It looks and this is encountered difficulties to write this code and taken many websites to understand. \\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "FBKvD6O_TY6e",
        "E9RqrlwdTfvl",
        "03jb4GZsBkBS",
        "jJDe71iLB616",
        "55W9AMdXCSpV",
        "4ulBZ6yhCi9F",
        "6SmvS7nSfbj8",
        "sZOhks1dXWEe"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}